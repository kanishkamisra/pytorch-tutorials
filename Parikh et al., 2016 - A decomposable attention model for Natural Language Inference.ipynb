{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from gensim.models import KeyedVectors\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from collections import defaultdict\n",
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = [0, 5, 6]\n",
    "train = []\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "for line in open(\"../snli_1.0/snli_1.0_test.txt\"):\n",
    "    entry = line.split(\"\\t\")\n",
    "    label, sentence1, sentence2 = [entry[i] for i in indices]\n",
    "    sentence1 = tokenizer.tokenize(sentence1.lower())\n",
    "    sentence2 = tokenizer.tokenize(sentence2.lower())\n",
    "    train.append((sentence1, sentence2, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence1: ['this', 'church', 'choir', 'sings', 'to', 'the', 'masses', 'as', 'they', 'sing', 'joyous', 'songs', 'from', 'the', 'book', 'at', 'a', 'church'], sentence2: ['the', 'church', 'has', 'cracks', 'in', 'the', 'ceiling'], label: neutral END\n",
      "sentence1: ['this', 'church', 'choir', 'sings', 'to', 'the', 'masses', 'as', 'they', 'sing', 'joyous', 'songs', 'from', 'the', 'book', 'at', 'a', 'church'], sentence2: ['the', 'church', 'is', 'filled', 'with', 'song'], label: entailment END\n"
     ]
    }
   ],
   "source": [
    "for entry in train[1:3]:\n",
    "    s1, s2, l = entry\n",
    "    print(\"sentence1: {}, sentence2: {}, label: {} END\".format(s1, s2, l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2i = defaultdict(lambda: len(w2i))\n",
    "l2i = defaultdict(lambda: len(l2i))\n",
    "UNK = w2i[\"<unk>\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2i[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>>, {'<unk>': 0})"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.Tensor(torch.rand(3, 4))\n",
    "softmax = nn.Softmax(dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5000, 0.3000, 0.8000])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sims = torch.Tensor([0.5, 0.3, 0.8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted = torch.sum(torch.t(torch.t(x) * sims), dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.7834704, 1.0361758, 0.9726609, 0.6262558], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(sims, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7544, 0.7832, 0.4038, 0.6040])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mv(torch.t(x), sims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1078, 0.1436, 0.0600, 0.1803],\n",
       "        [0.1393, 0.1145, 0.1772, 0.1967],\n",
       "        [0.5072, 0.5252, 0.1667, 0.2270]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.t(torch.t(x) * sims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "sims = torch.Tensor([[0.5, 0.3, 0.8], [0.2, 0.7, 0.4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3156, 0.2584, 0.4260],\n",
       "        [0.2584, 0.4260, 0.3156]])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax(sims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7544, 0.7832, 0.4038, 0.6040],\n",
       "        [0.6218, 0.5871, 0.5207, 0.6445]])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(sims, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_align(sims, embeddings):\n",
    "    assert(sims.size()[1] == embeddings.size()[0])\n",
    "    softmax = nn.Softmax(dim = 1)\n",
    "    sims = softmax(sims)\n",
    "    reweighted = torch.matmul(sims, embeddings)\n",
    "    return(reweighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4582, 0.4689, 0.2792, 0.4041],\n",
       "        [0.4537, 0.4439, 0.3483, 0.4620]])"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_align(sims, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example\n",
    "First sentence = \"Hey how are you?\"\n",
    "\n",
    "Second sentence = \"hey there!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove = KeyedVectors.load_word2vec_format(\"../pretrained_vectors/glove_50_word2vec.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_tensor = torch.FloatTensor(glove.vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = nn.Embedding.from_pretrained(glove_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_test_data(file):\n",
    "    with open(file) as f:\n",
    "        for line in f:\n",
    "            words = line.strip()\n",
    "            yield([w2i[x] for x in words.split(\" \")])\n",
    "\n",
    "example_train = [list(read_test_data(\"test_sentences.txt\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "pretrained_glove = np.random.uniform(-.25, .25, (len(w2i), 50))\n",
    "print(len(pretrained_glove))\n",
    "pretrained_glove[0] = 0\n",
    "print(len(pretrained_glove))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key: 6\n",
      "key: 3\n",
      "key: 5\n",
      "key: 4\n",
      "key: 2\n",
      "key: 1\n"
     ]
    }
   ],
   "source": [
    "for key in glove.vocab.keys():\n",
    "    if key in w2i:\n",
    "        print(\"key: {}\".format(w2i[key]))\n",
    "        pretrained_glove[w2i[key]] = glove[key]\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00],\n",
       "       [-7.00100005e-01,  3.67810011e-01,  3.44240010e-01,\n",
       "        -4.23180014e-01, -4.60180007e-02, -6.60719991e-01,\n",
       "        -3.39929998e-01,  1.82710007e-01, -9.28629994e-01,\n",
       "         5.68400025e-01, -4.38190013e-01,  7.08270013e-01,\n",
       "        -4.74590003e-01, -7.92689994e-02,  1.01870000e+00,\n",
       "         2.21300006e-01,  4.30729985e-01,  7.67189980e-01,\n",
       "         1.87739998e-01, -4.92139995e-01, -5.30629992e-01,\n",
       "         5.63790023e-01,  6.35710001e-01,  6.46220028e-01,\n",
       "         1.26489997e+00, -8.29010010e-01, -1.39030004e+00,\n",
       "         3.74900013e-01,  6.13160014e-01, -1.59940004e+00,\n",
       "         1.30050004e+00,  6.43469989e-01, -5.80039978e-01,\n",
       "         1.03719997e+00, -2.71560013e-01, -4.33820009e-01,\n",
       "         8.55400026e-01, -8.96700025e-01,  8.01760018e-01,\n",
       "        -3.33330005e-01, -1.76540002e-01, -1.22769997e-01,\n",
       "        -7.05079973e-01, -2.84119993e-01,  7.11489975e-01,\n",
       "        -1.34869993e-01,  4.95139994e-02, -8.13399971e-01,\n",
       "         3.42929989e-01,  1.03810000e+00],\n",
       "       [ 6.89379990e-01, -1.06440000e-01,  1.70829996e-01,\n",
       "        -3.75829995e-01,  7.51699984e-01,  7.81490002e-04,\n",
       "        -5.31019986e-01, -1.99029997e-01, -1.44189999e-01,\n",
       "         1.27480000e-01, -2.80380011e-01,  7.07229972e-01,\n",
       "        -5.41000009e-01,  1.96250007e-01,  9.66350019e-01,\n",
       "         6.05189979e-01,  4.09179986e-01, -3.16120014e-02,\n",
       "         5.38999975e-01, -8.70859981e-01, -2.09120005e-01,\n",
       "         5.68530023e-01,  6.59829974e-01,  1.45830005e-01,\n",
       "         1.01119995e+00, -2.07360005e+00, -1.12419999e+00,\n",
       "         5.96620026e-04,  7.03320026e-01, -8.26080024e-01,\n",
       "         3.44449997e+00,  3.29840004e-01, -3.53240013e-01,\n",
       "        -1.03349996e+00, -1.47530004e-01, -1.48739994e-01,\n",
       "        -4.12459999e-01,  3.34890008e-01,  1.98410004e-01,\n",
       "        -2.54779994e-01, -4.71929997e-01,  6.67010024e-02,\n",
       "         3.27769995e-01,  6.87810004e-01,  3.64279985e-01,\n",
       "         2.15220004e-01,  1.64940000e-01,  4.17609990e-01,\n",
       "        -2.25040004e-01,  6.14120007e-01],\n",
       "       [ 9.61929977e-01,  1.25160003e-02,  2.17329994e-01,\n",
       "        -6.53899983e-02,  2.68429995e-01,  3.35860014e-01,\n",
       "        -4.51119989e-01, -6.05470002e-01, -4.68450010e-01,\n",
       "        -1.84119999e-01,  6.09490015e-02,  1.95969999e-01,\n",
       "         2.26449996e-01,  3.28020006e-02,  4.24879998e-01,\n",
       "         4.96780008e-01,  6.53460026e-01, -2.74000000e-02,\n",
       "         1.78090006e-01, -1.19790006e+00, -4.06340003e-01,\n",
       "        -2.26589993e-01,  1.14950001e+00,  5.93420029e-01,\n",
       "        -2.37590000e-01, -9.32539999e-01, -5.25020003e-01,\n",
       "         5.12499996e-02,  3.22480015e-02, -7.27739990e-01,\n",
       "         4.24660015e+00,  6.05920017e-01,  3.33970010e-01,\n",
       "        -8.57540011e-01,  4.89499986e-01,  2.17439994e-01,\n",
       "        -1.34509996e-01,  9.49119963e-03, -5.41729987e-01,\n",
       "         1.88569993e-01, -6.45060003e-01,  1.26949996e-02,\n",
       "         7.34520018e-01,  1.00320005e+00,  4.18740004e-01,\n",
       "         1.65959999e-01, -7.10850000e-01,  1.40320003e-01,\n",
       "        -3.84680003e-01, -3.87120008e-01],\n",
       "       [-1.09190005e-03,  3.33240002e-01,  3.57430011e-01,\n",
       "        -5.40409982e-01,  8.20320010e-01, -4.93910015e-01,\n",
       "        -3.25879991e-01,  1.99720007e-03, -2.38289997e-01,\n",
       "         3.55540007e-01, -6.06549978e-01,  9.89319980e-01,\n",
       "        -2.17859998e-01,  1.12360001e-01,  1.14940000e+00,\n",
       "         7.32840002e-01,  5.11820018e-01,  2.92869985e-01,\n",
       "         2.83879995e-01, -1.35899997e+00, -3.79509985e-01,\n",
       "         5.09429991e-01,  7.07099974e-01,  6.29410028e-01,\n",
       "         1.05340004e+00, -2.17560005e+00, -1.32040000e+00,\n",
       "         4.00009990e-01,  1.57410002e+00, -1.65999997e+00,\n",
       "         3.77209997e+00,  8.69490027e-01, -8.04390013e-01,\n",
       "         1.83899999e-01, -3.43320012e-01,  1.07140001e-02,\n",
       "         2.39690006e-01,  6.67480007e-02,  7.01170027e-01,\n",
       "        -7.37020016e-01,  2.08770007e-01,  1.15640000e-01,\n",
       "        -1.51899993e-01,  8.59080017e-01,  2.26199999e-01,\n",
       "         1.65189996e-01,  3.63090008e-01, -4.56970006e-01,\n",
       "        -4.89690006e-02,  1.13160002e+00],\n",
       "       [ 6.84909999e-01,  3.23850006e-01, -1.15920000e-01,\n",
       "        -3.59250009e-01,  4.98890013e-01,  4.25410010e-02,\n",
       "        -4.01529998e-01, -3.67929995e-01, -6.14409983e-01,\n",
       "        -4.11480010e-01, -3.48199993e-01, -2.19520003e-01,\n",
       "        -2.23930001e-01, -6.49659991e-01,  8.54430020e-01,\n",
       "         3.35819989e-01,  2.93099999e-01,  1.65519997e-01,\n",
       "        -5.50819993e-01, -6.12770021e-01, -1.47679999e-01,\n",
       "         4.75510001e-01,  6.58770025e-01, -7.10299984e-02,\n",
       "         5.61469972e-01, -1.26510000e+00, -7.41169989e-01,\n",
       "         3.63649994e-01,  5.62300026e-01, -2.73649991e-01,\n",
       "         3.85060000e+00,  2.76450008e-01, -1.00900002e-01,\n",
       "        -7.15680003e-01,  1.85110003e-01, -1.23120002e-01,\n",
       "         5.66309988e-01, -2.23769993e-01, -1.68309994e-02,\n",
       "         5.75389981e-01, -5.17610013e-01,  3.38229984e-02,\n",
       "         1.96429998e-01,  6.34980023e-01, -2.48659998e-01,\n",
       "         3.87159996e-02, -5.05590022e-01,  1.78739995e-01,\n",
       "        -1.69300005e-01,  6.23750016e-02],\n",
       "       [ 4.18000013e-01,  2.49679998e-01, -4.12420005e-01,\n",
       "         1.21699996e-01,  3.45270008e-01, -4.44569997e-02,\n",
       "        -4.96879995e-01, -1.78619996e-01, -6.60229998e-04,\n",
       "        -6.56599998e-01,  2.78430015e-01, -1.47670001e-01,\n",
       "        -5.56770027e-01,  1.46579996e-01, -9.50950012e-03,\n",
       "         1.16579998e-02,  1.02040000e-01, -1.27920002e-01,\n",
       "        -8.44299972e-01, -1.21809997e-01, -1.68009996e-02,\n",
       "        -3.32789987e-01, -1.55200005e-01, -2.31309995e-01,\n",
       "        -1.91809997e-01, -1.88230002e+00, -7.67459989e-01,\n",
       "         9.90509987e-02, -4.21249986e-01, -1.95260003e-01,\n",
       "         4.00710011e+00, -1.85939997e-01, -5.22870004e-01,\n",
       "        -3.16810012e-01,  5.92130003e-04,  7.44489999e-03,\n",
       "         1.77780002e-01, -1.58969998e-01,  1.20409997e-02,\n",
       "        -5.42230010e-02, -2.98709989e-01, -1.57490000e-01,\n",
       "        -3.47579986e-01, -4.56370004e-02, -4.42510009e-01,\n",
       "         1.87849998e-01,  2.78489990e-03, -1.84110001e-01,\n",
       "        -1.15139998e-01, -7.85809994e-01]])"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fake embedding for first sentence: 4 words 6 dims\n",
    "first = torch.rand(4, 6)\n",
    "\n",
    "# fake embedding for second sentence: 2 words 6 dims\n",
    "second = torch.rand(2, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_f = nn.Linear(in_features=6, out_features=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformed1 = linear_f(first)\n",
    "# transformed2 = linear_f(second)\n",
    "transformed1, transformed2 = [linear_f(x) for x in [first, second]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3529, -0.4868,  0.1069, -0.0204, -0.4639, -0.2611,  0.0079],\n",
       "        [ 0.2474, -0.2837,  0.0292,  0.0028, -0.3747, -0.1736, -0.2402]],\n",
       "       grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected 3-dimensional tensor, but got 2-dimensional tensor for argument #1 'batch1' (while checking arguments for bmm)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-66bb95e2e97c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maligned1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformed1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformed2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0maligned2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformed2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformed1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected 3-dimensional tensor, but got 2-dimensional tensor for argument #1 'batch1' (while checking arguments for bmm)"
     ]
    }
   ],
   "source": [
    "aligned1 = torch.bmm(transformed1, torch.t(transformed2))\n",
    "aligned2 = torch.bmm(transformed2, torch.t(transformed1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.9375, 1.4376]], grad_fn=<MmBackward>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mm(transformed1[[1]], torch.t(transformed2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6133, 0.5491, 0.3429, 0.6659, 0.3139, 0.0492],\n",
       "        [0.0329, 0.5614, 0.8330, 0.9532, 0.2683, 0.4912],\n",
       "        [0.0598, 0.3936, 0.6898, 0.8176, 0.7837, 0.0418],\n",
       "        [0.8536, 0.0942, 0.2509, 0.8126, 0.1934, 0.2965]])"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7394, 0.7154, 0.3504, 0.7228, 0.4922, 0.4864],\n",
       "        [0.7376, 0.7225, 0.3476, 0.7094, 0.4772, 0.4806]],\n",
       "       grad_fn=<MmBackward>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## w_hat_a = get_align(aligned2, first) <- gets concatenated with sentence_b's embeddings\n",
    "get_align(aligned2, first)\n",
    "\n",
    "## w_hat_b = get_align(aligned1, second) <- gets concatenated with sentence_a's embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated2 = torch.cat((second, get_align(aligned2, first)), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated1 = torch.cat((first, get_align(aligned1, second)),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "## second layer\n",
    "linear_pair = nn.Linear(in_features = 2*6, out_features = 7)\n",
    "paired1 = linear_pair(concatenated1)\n",
    "paired2 = linear_pair(concatenated2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2812, -0.4679,  0.4616,  0.4147,  0.4096,  0.4283,  0.3498],\n",
       "        [ 0.4729, -0.5461,  0.5470,  0.2918,  0.3802,  0.5535,  0.5348],\n",
       "        [ 0.2250, -0.4903,  0.4564,  0.4962,  0.4911,  0.3095,  0.2507],\n",
       "        [ 0.1051, -0.3377,  0.4247,  0.4454,  0.3986,  0.3006,  0.3460]],\n",
       "       grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paired1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = torch.sum(paired1, 0)\n",
    "v2 = torch.sum(paired2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.0841, -1.8420,  1.8897,  1.6481,  1.6795,  1.5918,  1.4813,  0.6895,\n",
       "        -0.5484,  0.9582,  0.7871,  1.1696,  0.8275,  1.0047],\n",
       "       grad_fn=<CatBackward>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((v1, v2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1063, 0.0954, 0.1622, 0.0888, 0.0888, 0.0915, 0.1008, 0.0888, 0.0888,\n",
       "         0.0888],\n",
       "        [0.1125, 0.0889, 0.1595, 0.1058, 0.0889, 0.0889, 0.0889, 0.0889, 0.0889,\n",
       "         0.0889],\n",
       "        [0.1194, 0.0868, 0.1669, 0.0868, 0.0868, 0.0868, 0.1064, 0.0868, 0.0868,\n",
       "         0.0868],\n",
       "        [0.0939, 0.1021, 0.1605, 0.0992, 0.0885, 0.0885, 0.1020, 0.0885, 0.0885,\n",
       "         0.0885]], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax(relu(paired1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, **kwargs):\n",
    "        '''\n",
    "        PARAMS:\n",
    "        sent1 : tensor for sentence1\n",
    "        sent2 : tensor for sentence2\n",
    "        hidden_size : number of units in the hidden layer, 200 in the paper\n",
    "        output_size : number of units in the final layer (decision), 3 for entailment\n",
    "        emb_size : embedding size, 300 (might use glove instead to test)\n",
    "        \n",
    "        LAYERS:\n",
    "        linear_t : transformation layer (first layer in the network)\n",
    "        linear_p : paired layer which uses original word embeddings and their concatenation with the attended vectors\n",
    "        linead_d : decision layer which uses final concatenation of representations of sentences and decides if they\n",
    "                   entail or contradict each other or are neutral.\n",
    "        '''\n",
    "        super(MLP, self).__init__()\n",
    "        self.hidden_size = kwargs[\"HIDDEN_SIZE\"]\n",
    "        self.output_size = kwargs[\"OUTPUT_SIZE\"]\n",
    "        self.emb_size = kwargs[\"EMB_SIZE\"]\n",
    "        self.nwords = kwargs[\"SENT_LEN\"]\n",
    "        \n",
    "        self.embedding = nn.Embedding(self.nwords, self.emb_size)\n",
    "        self.linear_t = nn.Sequential(nn.Linear(self.emb_size, self.hidden_size), nn.ReLU(), nn.Linear(self.hidden_size, self.hidden_size))\n",
    "        self.linear_p = nn.Sequential(nn.Linear(self.emb_size*2, self.hidden_size), nn.ReLU(), nn.Linear(self.hidden_size, self.hidden_size))\n",
    "        self.linear_d = nn.Sequential(nn.Linear(self.emb_size*2, self.hidden_size), nn.ReLU(), nn.Linear(self.hidden_size, self.output_size), nn.Softmax())\n",
    "    \n",
    "#     def get_align(self, )\n",
    "    def forward(self, sentence1, sentence2):\n",
    "        sent1 = self.embedding(sentence1)\n",
    "        sent2 = self.embedding(sentence2)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP(EMB_SIZE = 50, HIDDEN_SIZE = 100, OUTPUT_SIZE = 3, SENT_LEN = 7)\n",
    "model.embedding.weight.data.copy_(torch.from_numpy(pretrained_glove))\n",
    "model.embedding.weight.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(torch.LongTensor([6,6]), torch.LongTensor([1,5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[1, 2, 3, 4], [1, 5], [6, 6]]]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
